# -*- coding: utf-8 -*-
"""Build a Random Forest  Classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ID63lCVuE4jWkYOI210AC11M35NKxO3c
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import re
import string
import nltk
import matplotlib.pyplot as plt
import seaborn as sns

from nltk.corpus import stopwords
from nltk.stem import PorterStemmer

from sklearn.model_selection import train_test_split, cross_val_score, cross_validate
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

data = pd.read_csv("/content/drive/MyDrive/Codveda_tasks/task 3/2) Stock Prices Data Set.csv")
data.head()

data.info()

print("Missing values before handling:")
print(data.isnull().sum())


data.dropna(inplace=True)

print("\nMissing values after handling:")
print(data.isnull().sum())

data = data.sort_values(by=['symbol', 'date']).reset_index(drop=True)

data['Target'] = (data['close'].shift(-1) > data['close']).astype(int)

data = data[:-1]

features = ['open', 'high', 'low', 'close', 'volume']
X = data[features]
y = data['Target']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

model = RandomForestClassifier(
    n_estimators=200,
    max_depth=8,
    random_state=42
)


cv_results = cross_validate(
    model, X, y,
    cv=5,
    scoring=['accuracy', 'precision', 'recall', 'f1'],
    return_train_score=False
)

for metric in ['accuracy', 'precision', 'recall', 'f1']:
    scores = cv_results[f'test_{metric}']
    print(f"{metric.capitalize()} (CV avg): {scores.mean():.4f}")

model.fit(X, y)

importances = model.feature_importances_
feature_importance_df = pd.DataFrame({
    'Feature': features,
    'Importance': importances
}).sort_values(by='Importance', ascending=False)

sns.barplot(x='Importance', y='Feature', data=feature_importance_df)
plt.title("Feature Importance - Random Forest")
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

# Make predictions on the test set
y_pred = model.predict(X_test)

cm = confusion_matrix(y_test, y_pred)

sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

data.to_csv('/content/drive/MyDrive/Codveda_tasks/task 3/processed_stock_data.csv', index=False)

